from tkinter import *
from tkinter import ttk
from tkinter import messagebox
from tkinter import font as tkFont
import os
import cv2
import numpy as np
import sys
from pydub import AudioSegment
import subprocess
import webbrowser
import math
import datetime
import threading
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# Global variable
path = os.getcwd()
working_path = path + "\\working_folder\\"
bin_path = path + "\\bin\\"
os.environ['PATH'] = bin_path + os.pathsep + os.environ.get('PATH','')
                    
array_1 = []
array_2 = []

# Constants

TEMP_FILENAME = "temp_list.txt"
TEMP_PREFIX = "out_"
FOURCC = cv2.VideoWriter_fourcc("m", "p", "4", "v")
DEFAULT_THREAD_NUM = 4
DEFAULT_IGNORE_FRAME_CNT = 0
SHOW_PROGRESS_SEG = 5
DEFAULT_LANGUAGE = "en"  # Default language: "cn" for Chinese, "en" for English

P_M_Y_CO = 0.074             #(right top) pause middle coefficient
P_M_X_CO = 0.112
P_L_X_CO = 0.125
M_P_M_Y_2_CO = 0.5           #this is the black point, other 3 are white point 
M_P_M_X_2_CO = 0.5           
M_P_L_Y_CO = 0.007           #middle pause
M_P_L_X_CO = 0.19
M_P_M_Y_CO = 0.043
M_P_R_Y_CO = 0.023
M_P_R_X_CO = 0.149

ACC_L_Y_CO = 0.095           #accelerate for lazy only
ACC_L_X_CO = 0.262
ACC_R_X_CO = 0.247

VP_Y_CO = 0.5       #valid pause
VP_X_1_CO = 0.046
VP_X_2_CO = 0.093
VP_X_3_CO = 0.139
VP_X_4_CO = 0.185

# Disabled following as new UI always works with first way of checking
#VP_2_Y_CO = 0.389   #second option to check valid pause
#VP_2_X_1_CO = 0.188 #wendi
#VP_2_X_2_CO = 0.197 #niaolong(mozu)
#VP_2_X_3_CO = 0.206 #m3
#VP_2_X_4_CO = 0.217 #panxie

WHITE_10 = np.array([240, 240, 240])
WHITE_9 = np.array([200, 200, 200])  # the number indicates the white level
GRAY = np.array([128, 128, 128])
BLACK_9 = np.array([30, 30, 30])
P_DIFF_TH = 10 # threshold
M_P_DIFF_TH = np.array([30, 30, 30]) # threshold
GRAY_LOWER = np.array([55, 55, 55])
GRAY_UPPER = np.array([130, 130, 130])

BLUE = 0
GREEN = 1
RED = 2
DARK_RED_TH = [20, 20, 90] # BGR <= <= >=
RED_RATIO_FOR_TOP_MARGIN = 0.3913
BLUE_TH = [130, 110, 50] # >= >= <=
BLUE_LOWER_PERC = 0.1
BLUE_UPPER_PERC = 0.25
LIGHT_GRAY_TH = [130, 130, 130]
LIGHT_GRAY_LOWER_PERC = 0.1
LIGHT_GRAY_UPPER_PERC = 0.25


MARGIN_TH = 500

# Import i18n module
from i18n import (
    t, get_current_language, set_language,
    register_language_change_callback, update_combobox_preserve_selection
)

# Initialize default language before creating any GUI elements
set_language(DEFAULT_LANGUAGE, notify=False)

# Global language variable (for backward compatibility)
current_language = get_current_language()

def change_language(event=None):
    """Handle language change"""
    global current_language
    idx = e_language.current()
    new_language = "cn" if idx == 0 else "en"
    set_language(new_language)
    current_language = get_current_language()
    # Callback is automatically triggered by set_language()

def update_all_text():
    """Update all GUI text elements based on current language"""
    win.title(t("window_title"))
    l_text_working_path.config(text=t("current_working_dir"))
    l_mode.config(text=t("select_mode"))
    # Only update b_show_desc if it still exists (not destroyed by show_desc)
    try:
        b_show_desc.config(text=t("show_desc"))
    except:
        pass
    l_top_margin.config(text=t("top_margin"))
    l_bottom_margin.config(text=t("bottom_margin"))
    l_left_margin.config(text=t("left_margin"))
    l_right_margin.config(text=t("right_margin"))
    l_thread_num.config(text=t("thread_num"))
    l_ignore_frame_cnt.config(text=t("ignore_frame_cnt"))
    b_save_settings.config(text=t("save_settings"))
    l_measure_margin_second.config(text=t("measure_margin_second"))
    b_measure_margin.config(text=t("measure_margin"))
    b_crop.config(text=t("crop_btn"))
    b_cut_without_crop.config(text=t("start_without_crop"))
    b_cut_with_crop.config(text=t("start_with_crop"))
    l_tutorial.config(text=t("tutorial"))
    l_start_second.config(text=t("start_second"))
    l_end_second.config(text=t("end_second"))
    l_manual_set_second.config(text=t("manual_set_second"))
    b_manual_set.config(text=t("manual_set"))
    b_manual_set_sample.config(text=t("sample_images"))
    b_manual_set_save.config(text=t("save_detection_points"))
    l_frame_desc.config(text=t("refer_sample"))
    l_frame_1_desc.config(text=t("frame_1_desc"))
    l_frame_2_desc.config(text=t("frame_2_desc"))
    l_manual_set_or_not.config(text=t("manual_set_or_not"))
    l_language.config(text=t("language"))
    # Update combobox values using helper function
    update_combobox_preserve_selection(
        e_mode,
        "mode_normal_audio_only", "mode_normal_keep_video",
        "mode_lazy_keep_valid", "mode_lazy_cut_all"
    )
    update_combobox_preserve_selection(
        e_manual_set_or_not,
        "no", "yes"
    )
    # Update description labels if they exist
    try:
        l3.config(text=t("lazy_mode_desc1") + "\n" + t("lazy_mode_desc2"), font=20, height=3, width=30)
        l3_2.config(text=t("lazy_mode_desc3"), font=20, width=30)
        l3_3.config(text=t("lazy_mode_desc3"), font=20)
        l4.config(text=t("normal_mode_desc1") + "\n" + t("normal_mode_desc2"), font=20, height=3, width=30)
        l4_2.config(text=t("normal_mode_desc3"), font=20, width=30)
        l4_3.config(text=t("normal_mode_desc3"), font=20)
    except:
        pass

def check_margin(top_margin, bottom_margin, left_margin, right_margin):
    if not (
        top_margin.replace("-", "").isdigit()
        and bottom_margin.replace("-", "").isdigit()
        and left_margin.replace("-", "").isdigit()
        and right_margin.replace("-", "").isdigit()
    ):
        messagebox.showerror(title=t("error_title"), message=t("margin_param_error"))
        return False
    if (
        int(top_margin) > MARGIN_TH
        or int(bottom_margin) > MARGIN_TH
        or int(left_margin) > MARGIN_TH
        or int(right_margin) > MARGIN_TH
    ):
        messagebox.showerror(title=t("error_title"), message=t("margin_too_large"))
        return False
    return True

def check_crop(top_margin, bottom_margin, left_margin, right_margin, video_name):
    if (
        int(top_margin) < 0
        or int(bottom_margin) < 0
        or int(left_margin) < 0
        or int(right_margin) < 0
    ):
        messagebox.showerror(title=t("error_title"), message=t("negative_margin_error"))
        return False
    if video_name == "aftercrop.mp4":
        messagebox.showerror(title=t("error_title"), message=t("aftercrop_name_error"))
        return False
    if os.path.exists(path + "/" + video_name):
        messagebox.showerror(title=t("error_title"), message=t("duplicate_file_error"))
        return False
    return True

def check_start_end_seconds(start_second, end_second):
    if not (start_second.isdigit() and end_second.isdigit()):
        messagebox.showerror(title=t("error_title"), message=t("start_end_param_error"))
        return False
    if int(start_second) >= int(end_second):
        messagebox.showerror(title=t("error_title"), message=t("end_must_be_greater"))
        return False
    return True

def check_file_and_return_path():
    file_cnt = 0
    working_folder_list = os.listdir(working_path)
    for lists in working_folder_list:
        file_cnt += 1
    if file_cnt == 1:
        if working_folder_list[0].startswith("out"):
            messagebox.showerror(title=t("error_title"), message=t("no_out_prefix"))
            return False
        return working_path + working_folder_list[0]
    messagebox.showerror(title=t("error_title"), message=t("single_file_required"))
    return False

def check_measure_margin_second(measure_margin_second):
    if not measure_margin_second.replace(".", "", 1).isdigit():
        messagebox.showerror(title=t("error_title"), message=t("measure_margin_error"))
        return False
    return True

def check_set_second(set_second):
    if not set_second.replace(".", "", 1).isdigit():
        messagebox.showerror(title=t("error_title"), message=t("manual_set_second_error"))
        return False
    return True  
    
def check_measure_margin_second_2(measure_margin_second, fps, frame_cnt):
    if measure_margin_second >= frame_cnt / fps:
        messagebox.showerror(title=t("error_title"), message=t("margin_exceeds_length"))
        return False
    return True

def check_thread_num(thread_num):
    if not(thread_num.isdigit() and 1 <= int(thread_num) <= 16):
        messagebox.showerror(title=t("error_title"), message=t("thread_num_error"))
        return False
    return True

def check_ignore_frame_cnt(ignore_frame_cnt):
    if not(ignore_frame_cnt.isdigit()):
        messagebox.showerror(title=t("error_title"), message=t("ignore_frame_error"))
        return False
    return True

def check_coordinates_setting():
    if not(len(array_1) == 4 and len(array_2) == 8):
        messagebox.showerror(title=t("error_title"), message=t("no_detection_points"))
        return False
    return True

def set_margin(top_margin, bottom_margin, left_margin, right_margin):
    e_top_margin.delete(0, END)
    e_bottom_margin.delete(0, END)
    e_left_margin.delete(0, END)
    e_right_margin.delete(0, END)
    e_top_margin.insert(0, top_margin)
    e_bottom_margin.insert(0, bottom_margin)
    e_left_margin.insert(0, left_margin)
    e_right_margin.insert(0, right_margin)      
    
def set_thread_num(thread_num):
    e_thread_num.delete(0, END)
    e_thread_num.insert(0, thread_num)    
    
def set_ignore_frame_cnt(ignore_frame_cnt):
    e_ignore_frame_cnt.delete(0, END)
    e_ignore_frame_cnt.insert(0, ignore_frame_cnt)    

def set_coordinates():
    if os.path.exists(path + "/检测点.txt"):
        f = open(path + "/检测点.txt")  # Detection points

        for i in range(4):
            coord = [int(f.readline()) , int(f.readline())]
            array_1.append(coord)
            
        for i in range(4):
            coord = [int(f.readline()) , int(f.readline())]
            array_2.append(coord)
        
        valid_pause_y = int(f.readline())
        
        for i in range(4):
            coord = [valid_pause_y , int(f.readline())]
            array_2.append(coord)
        
        set_coordinates_labels()        
        
        #print(array_1)
        #print(array_2)
        
        f.close()
   
def set_coordinates_labels():
    if len(array_1) == 4 and len(array_2) == 8:
        l_acc_right.config(text=str(array_1[0][0])+","+str(array_1[0][1]))
        l_acc_left.config(text=str(array_1[1][0])+","+str(array_1[1][1]))
        l_pause_middle.config(text=str(array_1[2][0])+","+str(array_1[2][1]))
        l_pause_left.config(text=str(array_1[3][0])+","+str(array_1[3][1]))
        l_middle_pause_left.config(text=str(array_2[0][0])+","+str(array_2[0][1]))
        l_middle_pause_middle_2.config(text=str(array_2[1][0])+","+str(array_2[1][1]))
        l_middle_pause_middle.config(text=str(array_2[2][0])+","+str(array_2[2][1]))
        l_middle_pause_right.config(text=str(array_2[3][0])+","+str(array_2[3][1]))
        l_valid_pause.config(text=str(array_2[4][0])+","+str(array_2[4][1])+","+str(array_2[5][1])+","+str(array_2[6][1])+","+str(array_2[7][1]))   
    else:
        l_acc_right.config(text="y,x")
        l_acc_left.config(text="y,x")
        l_pause_middle.config(text="y,x")
        l_pause_left.config(text="y,x")
        l_middle_pause_left.config(text="y,x")
        l_middle_pause_middle_2.config(text="y,x")
        l_middle_pause_middle.config(text="y,x")
        l_middle_pause_right.config(text="y,x")
        l_valid_pause.config(text="y,x1,x2,x3,x4")
 
def get_video_info(video_path):
    cap = cv2.VideoCapture(video_path)
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    lgt = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    hgt = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    cap.release()
    return fps, lgt, hgt, frame_cnt  
    
def get_frame_cnt(video_path):
    cap = cv2.VideoCapture(video_path)
    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    cap.release()
    return frame_cnt  
    
def measure_margin(measure_margin_second):
    if check_measure_margin_second(measure_margin_second):
        video_path = check_file_and_return_path()
        if video_path:
            fps, lgt, hgt, frame_cnt = get_video_info(video_path)
            if check_measure_margin_second_2(
                float(measure_margin_second), fps, frame_cnt
            ):
                cap = cv2.VideoCapture(video_path)
                top_margin = MARGIN_TH
                bottom_margin = MARGIN_TH
                left_margin = MARGIN_TH
                right_margin = MARGIN_TH

                cap.set(
                    cv2.CAP_PROP_POS_FRAMES, int(fps * float(measure_margin_second))
                )
                ret, frame = cap.read()
                cap.release()

                flag = False
                red_cnt = 1
                for rgt_check in range(1, int(lgt / 2)):
                    for y in range(int(hgt / 2)):
                        x = lgt - rgt_check
                        if (
                            frame[y, x][RED] >= DARK_RED_TH[RED]
                            and frame[y, x][BLUE] <= DARK_RED_TH[BLUE]
                            and frame[y, x][GREEN] <= DARK_RED_TH[GREEN]
                        ):
                            right_margin = rgt_check - 1
                            first_y = y
                            y += 1
                            while (
                                frame[y, x][RED] >= DARK_RED_TH[RED]
                                and frame[y, x][BLUE] <= DARK_RED_TH[BLUE]
                                and frame[y, x][GREEN] <= DARK_RED_TH[GREEN]
                            ):
                                y += 1
                                red_cnt += 1
                            # print(red_cnt)
                            top_margin = int(
                                first_y - red_cnt * RED_RATIO_FOR_TOP_MARGIN
                            )

                            flag = True
                            break
                    if flag:
                        break

                for bot_check in range(1, int(hgt / 2)):
                    blue_cnt = 0
                    for x in range(lgt):
                        y = hgt - bot_check
                        if (
                            frame[y, x][BLUE] >= BLUE_TH[BLUE]
                            and frame[y, x][GREEN] >= BLUE_TH[GREEN]
                            and frame[y, x][RED] <= BLUE_TH[RED]
                        ):
                            blue_cnt += 1
                    if BLUE_LOWER_PERC < blue_cnt / lgt < BLUE_UPPER_PERC:
                        bottom_margin = bot_check - 1
                        break

                for x in range(int(lgt / 2)):
                    light_grey_cnt=0
                    for y in range(hgt):
                        if(frame[y,x][BLUE]>=LIGHT_GRAY_TH[BLUE] and frame[y,x][GREEN]>=LIGHT_GRAY_TH[GREEN] 
                                and frame[y,x][RED]>=LIGHT_GRAY_TH[RED]):
                            light_grey_cnt=light_grey_cnt+1
                        y=y+1
                    if LIGHT_GRAY_LOWER_PERC < light_grey_cnt/hgt < LIGHT_GRAY_UPPER_PERC:
                        left_margin=x
                        break
                    x=x+1          
                        

                if (
                    top_margin >= MARGIN_TH
                    or bottom_margin >= MARGIN_TH
                    or left_margin >= MARGIN_TH
                    or right_margin >= MARGIN_TH
                ):
                    messagebox.showerror(
                        title=t("error_title"), message=t("calculation_error")
                    )
                    return False
                set_margin(top_margin, bottom_margin, left_margin, right_margin)
                messagebox.showinfo(title=t("info_title"), message=t("margin_filled"))
                return True
            else:
                return False

             
def cut_with_crop(mode, start_second, end_second, thread_num, measure_margin_second, ignore_frame_cnt):
    if check_ignore_frame_cnt(ignore_frame_cnt):
        if check_thread_num(thread_num):
            if check_start_end_seconds(start_second, end_second):
                if measure_margin(measure_margin_second):
                    if crop(                    
                        e_top_margin.get(),
                        e_bottom_margin.get(),
                        e_left_margin.get(),
                        e_right_margin.get(),
                    ):
                        if measure_margin(measure_margin_second):
                            cut_without_crop(
                                mode,  
                                e_top_margin.get(),
                                e_bottom_margin.get(),
                                e_left_margin.get(),
                                e_right_margin.get(),
                                start_second,
                                end_second,
                                thread_num,
                                ignore_frame_cnt
                            )

def crop(top_margin, bottom_margin, left_margin, right_margin):
    video_path = check_file_and_return_path()
    if video_path:
        if check_margin(top_margin, bottom_margin, left_margin, right_margin):
            orig_name = os.listdir(working_path)[0]
            if check_crop(
                top_margin, bottom_margin, left_margin, right_margin, orig_name
            ):
                cap = cv2.VideoCapture(video_path)
                lgt = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) 
                hgt = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) 
                cap.release()
                out = working_path + "aftercrop.mp4"
                if (lgt - int(left_margin) - int(right_margin)) % 2 == 1:
                    W = str(lgt - int(left_margin) - int(right_margin) + 1)
                else:
                    W = str(lgt - int(left_margin) - int(right_margin))
                if (hgt - int(top_margin) - int(bottom_margin)) % 2 == 1:
                    H = str(hgt - int(top_margin) - int(bottom_margin) + 1)
                else:                    
                    H = str(hgt - int(top_margin) - int(bottom_margin))
                X = left_margin
                Y = top_margin
                #print(X, Y, W, H)              
                
                tc = TimeCost()
                tc.time_start(t("log_timing_cropping"))

                subprocess.call('ffmpeg -loglevel quiet -i "'
                    + video_path + '" -b:v 0 -vf crop=' 
                    + W + ':' + H + ':' + X + ':' + Y + ' '+out,shell = True)
                os.rename(video_path, "./" + orig_name)
                logger.info(t("log_crop_complete"))

                tc.time_end()
                # set_margin(0, 0, 0, 0)
                # print("Margins reset to 0")
                return True

def show_desc():
    global l3, l3_2, l3_3, l4, l4_2, l4_3
    b_show_desc.destroy()
    l3 = Label(win, text=t("lazy_mode_desc1"), font=20, height=3, width=30)
    l3_2 = Label(win, text=t("lazy_mode_desc2"), font=20, width=30)
    l3_3 = Label(win, text=t("lazy_mode_desc3"), font=20)
    l4 = Label(win, text=t("normal_mode_desc1"), font=20, height=3, width=30)
    l4_2 = Label(win, text=t("normal_mode_desc2"), font=20, width=30)
    l4_3 = Label(win, text=t("normal_mode_desc3"), font=20)
    l3.grid(row=2)
    l3_2.grid(row=2, column=1)
    l3_3.grid(row=2, column=2)
    l4.grid(row=3)
    l4_2.grid(row=3, column=1)
    l4_3.grid(row=3, column=2)

def save_settings(mode_i, top_margin, bottom_margin, left_margin, right_margin, thread_num, ignore_frame_cnt):
    if check_thread_num(thread_num):
        if check_margin(top_margin, bottom_margin, left_margin, right_margin):
            f = open(path + "/设置.txt", "w+")  # Settings
            f.write(str(mode_i) + "\n")
            f.write(top_margin + "\n")
            f.write(bottom_margin + "\n")
            f.write(left_margin + "\n")
            f.write(right_margin + "\n")
            f.write(thread_num + "\n")
            f.write(ignore_frame_cnt + "\n")
            f.write(str(current_language) + "\n")  # Save language preference
            f.close()
            messagebox.showinfo(title=t("info_title"), message=t("settings_saved"))

def manual_set_save():
    if check_coordinates_setting():
        f = open(path + "/检测点.txt", "w+")  # Save detection points
        f.write(str(array_1[0][0]) + "\n")
        f.write(str(array_1[0][1]) + "\n")
        f.write(str(array_1[1][0]) + "\n")
        f.write(str(array_1[1][1]) + "\n")
        f.write(str(array_1[2][0]) + "\n")
        f.write(str(array_1[2][1]) + "\n")
        f.write(str(array_1[3][0]) + "\n")
        f.write(str(array_1[3][1]) + "\n")
        f.write(str(array_2[0][0]) + "\n")
        f.write(str(array_2[0][1]) + "\n")
        f.write(str(array_2[1][0]) + "\n")
        f.write(str(array_2[1][1]) + "\n")
        f.write(str(array_2[2][0]) + "\n")
        f.write(str(array_2[2][1]) + "\n")
        f.write(str(array_2[3][0]) + "\n")
        f.write(str(array_2[3][1]) + "\n")
        f.write(str(array_2[4][0]) + "\n")
        f.write(str(array_2[4][1]) + "\n")
        f.write(str(array_2[5][1]) + "\n")
        f.write(str(array_2[6][1]) + "\n")
        f.write(str(array_2[7][1]) + "\n")
        f.close()
        messagebox.showinfo(title=t("info_title"), message=t("detection_points_saved"))

def cut_without_crop(
    mode, top_margin, bottom_margin, left_margin, right_margin, start_second, end_second, thread_num, ignore_frame_cnt
):
    if e_manual_set_or_not.current() == 0 or check_coordinates_setting():
        if check_ignore_frame_cnt(ignore_frame_cnt):
            if check_thread_num(thread_num):
                if check_start_end_seconds(start_second, end_second):
                    video_path = check_file_and_return_path()
                    if video_path:
                        cap = cv2.VideoCapture(video_path)
                        frame_cnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)
                        fps = cap.get(cv2.CAP_PROP_FPS)
                        cap.release()
                        if check_margin(top_margin, bottom_margin, left_margin, right_margin):
                            if frame_cnt / int(fps) <= int(end_second):
                                messagebox.showerror(title=t("error_title"), message=t("end_exceeds_video"))
                            else:
                                if int(fps) != fps:  # warning only not error
                                    messagebox.showinfo(
                                        title=t("warning_title"),
                                        message=t("fps_warning"),
                                    )
                                tc = TimeCost()
                                tc.time_start(t("log_timing_full_process"))
                                # Get translated mode name for display
                                mode_names = [t("mode_normal_audio_only"), t("mode_normal_keep_video"), t("mode_lazy_keep_valid"), t("mode_lazy_cut_all")]
                                logger.info(mode_names[mode] + " " + t("log_started"))
                                if mode in [2, 3]:  # Lazy mode indices
                                    lazy_version(
                                        video_path,
                                        mode,
                                        int(top_margin),
                                        int(bottom_margin),
                                        int(left_margin),
                                        int(right_margin),
                                        int(start_second),
                                        int(end_second),
                                        int(thread_num)
                                    )
                                    # already know these variables are int, thus cast here instead of inside
                                    logger.info(t("log_lazy_complete"))
                                else:  # normal mode otherwise
                                    normal_version(
                                        video_path,
                                        mode,
                                        int(top_margin),
                                        int(bottom_margin),
                                        int(left_margin),
                                        int(right_margin),
                                        int(start_second),
                                        int(end_second),
                                        int(thread_num)
                                    )
                                    logger.info(t("log_normal_complete"))
                                tc.time_end()

def jump_to_tutorial(event):
    webbrowser.open("https://www.bilibili.com/video/BV1qg411r7dV", new=0)


def set_coordinates_sample():
    img2 = cv2.imread('sample2.jpg')
    img = cv2.imread('sample1.jpg')
    if img2 is None or img is None:
        messagebox.showerror(title=t("error_title"), message=t("sample_image_missing"))
    else:
        cv2.namedWindow("Sample_2", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("Sample_2", (960,540))
        cv2.imshow('Sample_2', img2)

        cv2.namedWindow("Sample_1", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("Sample_1", (960,540))
        cv2.imshow('Sample_1', img)

def set_coordinates_manually(set_second_1, set_second_2):
    array_1.clear()
    array_2.clear()
    if check_set_second(set_second_1):
        if check_set_second(set_second_2):
            video_path = check_file_and_return_path()
            if video_path:
                fps, lgt, hgt, frame_cnt = get_video_info(video_path)
                cap = cv2.VideoCapture(video_path)

                cap.set(
                    cv2.CAP_PROP_POS_FRAMES, int(fps * float(set_second_1))
                )
                ret, frame = cap.read()

                if ret:
                    cv2.namedWindow("Frame_1", cv2.WINDOW_NORMAL)
                    messagebox.showinfo(title=t("info_title"), message=t("click_4_points"))
                    cv2.setWindowProperty("Frame_1", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
                    cv2.imshow('Frame_1', frame)

                    cv2.setMouseCallback('Frame_1', mouse_callback_1, array_1)

                else:
                    messagebox.showerror(title=t("error_title"), message=t("frame_read_failed"))
                cv2.waitKey()
                if len(array_1) < 4:
                    messagebox.showerror(title=t("error_title"), message=t("not_4_points"))
                    if cv2.getWindowProperty('Frame_1', cv2.WND_PROP_VISIBLE):
                        cv2.destroyWindow('Frame_1')
                else:
                    cap.set(
                        cv2.CAP_PROP_POS_FRAMES, int(fps * float(set_second_2))
                    )
                    ret, frame = cap.read()
                    cap.release()

                    if ret:
                        cv2.namedWindow("Frame_2", cv2.WINDOW_NORMAL)
                        messagebox.showinfo(title=t("info_title"), message=t("click_8_points"))
                        cv2.setWindowProperty("Frame_2", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
                        cv2.imshow('Frame_2', frame)

                        cv2.setMouseCallback('Frame_2', mouse_callback_2, array_2)

                    else:
                        messagebox.showerror(title=t("error_title"), message=t("frame_read_failed"))
                    cv2.waitKey()
                    if len(array_2) < 8:
                        messagebox.showerror(title=t("error_title"), message=t("not_8_points"))
                        if cv2.getWindowProperty('Frame_2', cv2.WND_PROP_VISIBLE):
                            cv2.destroyWindow('Frame_2')                                                
                set_coordinates_labels()
                        
def mouse_callback_1(event, x, y, flags, param):
    if len(param) >= 4:
        cv2.destroyWindow('Frame_1')
    elif event == cv2.EVENT_LBUTTONDOWN:
        coord = [y, x]
        param.append(coord)
        #print(f"ROI selected: ({y},{x}) ")
        #print(param)
        
def mouse_callback_2(event, x, y, flags, param):
    if len(param) >= 8:
        cv2.destroyWindow('Frame_2')
    elif event == cv2.EVENT_LBUTTONDOWN:
        coord = [y, x]
        param.append(coord)
        #print(f"ROI selected: ({y},{x}) ")
        #print(param)
            
class PointCoordinates:
    def __init__(self):
        self.p_m_y, self.p_m_x = 0, 0
        self.p_l_y, self.p_l_x = 0, 0
        self.m_p_m_y_2, self.m_p_m_x_2 = 0, 0

        self.m_p_l_y, self.m_p_l_x = 0, 0
        self.m_p_m_y, self.m_p_m_x = 0, 0
        self.m_p_r_y, self.m_p_r_x = 0, 0

        self.acc_l_y, self.acc_l_x = 0, 0
        self.acc_r_y, self.acc_r_x = 0, 0

        self.vp_y, self.vp_x_1, self.vp_x_2, self.vp_x_3, self.vp_x_4 = 0, 0, 0, 0, 0
        # self.vp_2_y, self.vp_2_x_1, self.vp_2_x_2, self.vp_2_x_3, self.vp_2_x_4 = (
            # 0,
            # 0,
            # 0,
            # 0,
            # 0
        # )

    def calculate_or_use_coordinates(
        self, lgt, hgt, top_margin, bottom_margin, left_margin, right_margin
    ):
        if e_manual_set_or_not.current() == 1:
            self.acc_r_y = array_1[0][0]
            self.acc_r_x = array_1[0][1]
            self.acc_l_y = array_1[1][0]
            self.acc_l_x = array_1[1][1]
            self.p_m_y = array_1[2][0]
            self.p_m_x = array_1[2][1]
            self.p_l_y = array_1[3][0]
            self.p_l_x = array_1[3][1]
            self.m_p_l_y = array_2[0][0]
            self.m_p_l_x = array_2[0][1]
            self.m_p_m_y_2 = array_2[1][0]
            self.m_p_m_x_2 = array_2[1][1]
            self.m_p_m_y = array_2[2][0]
            self.m_p_m_x = array_2[2][1]
            self.m_p_r_y = array_2[3][0]
            self.m_p_r_x = array_2[3][1]
            self.vp_y = array_2[4][0]
            self.vp_x_1 = array_2[4][1]
            self.vp_x_2 = array_2[5][1]
            self.vp_x_3 = array_2[6][1]
            self.vp_x_4 = array_2[7][1]
        else:
            act_hgt = hgt - top_margin - bottom_margin
            act_lgt = lgt - left_margin - right_margin
            
            if act_lgt * 1080 < act_hgt * 1920:
                mdf_hgt = int(round(act_lgt / 1920 * 1080, 0))
            else:
                mdf_hgt = act_hgt

            self.p_m_y = int(round(P_M_Y_CO * mdf_hgt + top_margin, 0))
            self.p_m_x = int(round(lgt - P_M_X_CO * mdf_hgt - right_margin, 0))
            # right top || middle
            self.p_l_y = self.p_m_y
            self.p_l_x = int(round(lgt - P_L_X_CO * mdf_hgt - right_margin, 0))
            # right top || left

            self.m_p_m_y_2 = int(round(M_P_M_Y_2_CO * act_hgt + top_margin, 0))
            self.m_p_m_x_2 = int(
                round(M_P_M_X_2_CO * (lgt - left_margin - right_margin) + left_margin, 0)
            )
            # middle PAUSE point (black point)

            self.m_p_l_y = int(round(self.m_p_m_y_2 + M_P_L_Y_CO * mdf_hgt, 0))
            self.m_p_l_x = int(round(self.m_p_m_x_2 - M_P_L_X_CO * mdf_hgt, 0))
            # middle PAUSE left point (white point)
            self.m_p_m_y = int(round(self.m_p_m_y_2 + M_P_M_Y_CO * mdf_hgt, 0))
            self.m_p_m_x = self.m_p_m_x_2
            # middle PAUSE middle point (white point)
            self.m_p_r_y = int(round(self.m_p_m_y_2 - M_P_R_Y_CO * mdf_hgt, 0))
            self.m_p_r_x = int(round(self.m_p_m_x_2 + M_P_R_X_CO * mdf_hgt, 0))
            # middle PAUSE right point (white point)

            self.acc_l_y = int(round(ACC_L_Y_CO * mdf_hgt + top_margin, 0))
            self.acc_l_x = int(round(lgt - ACC_L_X_CO * mdf_hgt - right_margin, 0))
            self.acc_r_y = self.acc_l_y
            self.acc_r_x = int(round(lgt - ACC_R_X_CO * mdf_hgt - right_margin, 0))

            self.vp_y = int(round(VP_Y_CO * act_hgt + top_margin, 0))
            self.vp_x_1 = int(round(VP_X_1_CO * mdf_hgt + left_margin, 0))
            self.vp_x_2 = int(round(VP_X_2_CO * mdf_hgt + left_margin, 0))
            self.vp_x_3 = int(round(VP_X_3_CO * mdf_hgt + left_margin, 0))
            self.vp_x_4 = int(round(VP_X_4_CO * mdf_hgt + left_margin, 0))

            # self.vp_2_y = int(
                # round(VP_Y_CO * act_hgt + top_margin - (VP_Y_CO - VP_2_Y_CO) * mdf_hgt, 0)
            # )
            # self.vp_2_x_1 = int(round(VP_2_X_1_CO * mdf_hgt + left_margin, 0))
            # self.vp_2_x_2 = int(round(VP_2_X_2_CO * mdf_hgt + left_margin, 0))
            # self.vp_2_x_3 = int(round(VP_2_X_3_CO * mdf_hgt + left_margin, 0))
            # self.vp_2_x_4 = int(round(VP_2_X_4_CO * mdf_hgt + left_margin, 0))

            #print(self.p_m_y, self.p_m_x)
            #print(self.p_l_y, self.p_l_x)
            #print(self.m_p_m_y_2, self.m_p_m_x_2)
            #print(self.m_p_l_y, self.m_p_l_x)
            #print(self.m_p_m_y, self.m_p_m_x)
            #print(self.m_p_r_y, self.m_p_r_x)
            #print(self.acc_l_y, self.acc_l_x)
            #print(self.acc_r_y, self.acc_r_x)
            #print(self.vp_y, self.vp_x_1, self.vp_x_2, self.vp_x_3, self.vp_x_4)
            #print(self.vp_2_y, self.vp_2_x_1, self.vp_2_x_2, self.vp_2_x_3, self.vp_2_x_4)
        
        
def is_pause(frame, pc):
    if abs(
            float(sum(frame[pc.p_l_y, pc.p_l_x]) / len(frame[pc.p_l_y, pc.p_l_x]))
            - float(sum(frame[pc.p_m_y, pc.p_m_x]) / len(frame[pc.p_m_y, pc.p_m_x]))
            ) < P_DIFF_TH:
        return True
    white_points = [
        (pc.m_p_l_y, pc.m_p_l_x),
        (pc.m_p_m_y, pc.m_p_m_x),
        (pc.m_p_r_y, pc.m_p_r_x)
    ]
    if all(all(frame[y, x] > WHITE_10) for y, x in white_points):
        return True 
    if (
        all(frame[pc.m_p_m_y, pc.m_p_m_x] > GRAY)
        and all(abs(frame[pc.m_p_m_y, pc.m_p_m_x] - frame[pc.m_p_l_y, pc.m_p_l_x]) < M_P_DIFF_TH)
        and all(abs(frame[pc.m_p_m_y, pc.m_p_m_x] - frame[pc.m_p_r_y, pc.m_p_r_x]) < M_P_DIFF_TH)
        and all(abs(frame[pc.m_p_l_y, pc.m_p_l_x] - frame[pc.m_p_r_y, pc.m_p_r_x]) < M_P_DIFF_TH)
        and all(frame[pc.m_p_m_y_2, pc.m_p_m_x_2] < GRAY)
    ):
        return True
    return False

def is_acceleration(frame, pc):
    if all(frame[pc.acc_r_y, pc.acc_r_x] > WHITE_9) and any(
        frame[pc.acc_l_y, pc.acc_l_x] < WHITE_9
    ):
        return False
    return True

def is_valid_pause(frame, pc):
    #if all(frame[pc.vp_y +5, pc.vp_x_1]  < BLACK_9):
    for dy in [0, -1, 1]:  # offset
        row = pc.vp_y  + dy 
        if (all(GRAY_LOWER <= frame[row, pc.vp_x_1])
            and all(frame[row, pc.vp_x_1] <= GRAY_UPPER) 
            and all(GRAY_LOWER <= frame[row, pc.vp_x_2])
            and all(frame[row, pc.vp_x_2] <= GRAY_UPPER) 
            and all(GRAY_LOWER <= frame[row, pc.vp_x_3])
            and all(frame[row, pc.vp_x_3] <= GRAY_UPPER) 
            and all(GRAY_LOWER <= frame[row, pc.vp_x_4])
            and all(frame[row, pc.vp_x_4] <= GRAY_UPPER) 
        ):
            #print(frame[row, pc.vp_x_1],frame[row, pc.vp_x_2],frame[row, pc.vp_x_3],frame[row, pc.vp_x_4])
            return True 
    #white_cols = (pc.vp_2_x_1,  pc.vp_2_x_2,  pc.vp_2_x_3,  pc.vp_2_x_4) 
    #return any(all(frame[pc.vp_2_y, col] > WHITE_10) for col in white_cols)

def expand_valid_pause_range(frame_cnt, pause_y_n, vp_y_n):
    for i in range(1, frame_cnt - 1):
        if vp_y_n[i] == True and vp_y_n[i - 1] == False and pause_y_n[i - 1] == True:
            a = i - 1
            while pause_y_n[a] == True and a >= 0:
                vp_y_n[a] = True
                a -= 1
        elif vp_y_n[i] == True and vp_y_n[i + 1] == False and pause_y_n[i + 1] == True:
            a = i + 1
            while pause_y_n[a] == True and a < frame_cnt:
                vp_y_n[a] = True
                a += 1
            i = a
            
def remove_ignore_frame_cnt_part(frame_cnt, keep_frame_y_n, vp_y_n):
    a = 0
    start = 0
    flag = 0 
    #flag 0 means keep frame_y_n = True, 1 means vp_y_n = True
    for i in range(1, frame_cnt - 1):
        if keep_frame_y_n[i] == True:
            if flag == 0:
                a += 1
            else:
                if a <= int(e_ignore_frame_cnt.get()):
                    for j in range(start, i - 1):
                        vp_y_n[j] = False
                a = 0
                start = i
                flag = 0
        elif vp_y_n[i] == True:
            if flag == 1:
                a += 1
            else:
                if a <= int(e_ignore_frame_cnt.get()):
                    for j in range(start, i - 1):
                        keep_frame_y_n[j] = False
                a = 0
                start = i
                flag = 1

def print_progress(i, start, end, start_key, end_key, *format_args):
    if i == start:
        logger.info(t(start_key).format(*format_args) if format_args else t(start_key))
    elif i == end:
        logger.info(t(end_key).format(*format_args) if format_args else t(end_key))
    elif (
        (i - start) % ((end - start) / SHOW_PROGRESS_SEG) < 1 and i > start and i < end
    ):
        logger.info(f"{(i - start) / (end - start):.0%}")

def get_file_suffix(vp_value, pause_value):
    if vp_value == True:
        return t("valid_pause")
    elif pause_value == True:
        return t("invalid_pause")
    else:
        return ""

def cleanup(working_path):
    tc = TimeCost()
    tc.time_start(t("log_timing_cleaning_segments"))    
    for root, dirs, files in os.walk(working_path):
        for name in files:
            full_file_path = os.path.join(root, name)
            if name.startswith(TEMP_PREFIX):
                os.remove(full_file_path)
            elif get_frame_cnt(full_file_path) <= int(e_ignore_frame_cnt.get()) and os.path.splitext(full_file_path)[-1].split(".")[1] == 'mp4':
                os.remove(full_file_path)
                logger.info(t("log_segment_deleted").format(name))
    tc.time_end()


def update_entry_state(event):
    if e_manual_set_or_not.current() == 1:
        e_top_margin.config(state="disable")
        e_bottom_margin.config(state="disable")
        e_left_margin.config(state="disable")
        e_right_margin.config(state="disabled")
        b_save_settings.config(state="disabled")
        e_measure_margin_second.config(state="disabled")
        b_measure_margin.config(state="disabled")
        b_crop.config(state="disabled")
        b_cut_with_crop.config(state="disabled")
        e_manual_set_second_1.config(state="normal")
        e_manual_set_second_2.config(state="normal")
        b_manual_set.config(state="normal")
        b_manual_set_sample.config(state="normal")
        b_manual_set_save.config(state="normal")  
    else:
        e_top_margin.config(state="normal")
        e_bottom_margin.config(state="normal")
        e_left_margin.config(state="normal")
        e_right_margin.config(state="normal")
        b_save_settings.config(state="normal")
        e_measure_margin_second.config(state="normal")
        b_measure_margin.config(state="normal")
        b_crop.config(state="normal")
        b_cut_with_crop.config(state="normal")
        e_manual_set_second_1.config(state="disabled")
        e_manual_set_second_2.config(state="disabled")
        b_manual_set.config(state="disabled")
        b_manual_set_sample.config(state="disabled")  
        b_manual_set_save.config(state="disabled")  

class TimeCost:
    def __init__(self):
        self.start = datetime
        self.end = datetime

    def time_start(self, process_name):
        self.start = datetime.datetime.now()
        logger.info(t("log_timing_for").format(process_name))
        logger.info(t("log_timing_started").format(self.start))

    def time_end(self):
        self.end = datetime.datetime.now()
        logger.info(t("log_timing_ended").format(self.end))
        logger.info(t("log_time_elapsed").format(self.end - self.start))


def lazy_pause_analyze(
    process_num, start_f, end_f, start, end, cap, pc, pause_y_n, vp_y_n, keep_frame_y_n
):   
    cap.set(cv2.CAP_PROP_POS_FRAMES, start)
    skip = True
    for i in range(start, end + 1):
        if i <= end_f:
            ret, frame = cap.read()
        if i < start_f or i > end_f:
            keep_frame_y_n[i] = True
        else:
            # try: 
               # is_pause(frame, pc)
            # except Exception as e:
                # print(frame[pc.p_l_y, pc.p_l_x])
                # if os.path.exists(path + "/log.txt"):
                    # f = open(path + "/log.txt", "a")                  
                    # f.write("error frame is " + str(i) + "\n")
                    # f.close()
            # else:
            if not is_pause(frame, pc):
                if not is_acceleration(frame, pc):
                    if skip:
                        skip = False
                    else:
                        skip = True
                        keep_frame_y_n[i] = True
                else:
                    keep_frame_y_n[i] = True
            else:
                pause_y_n[i] = True
                if is_valid_pause(frame, pc):
                    vp_y_n[i] = True
        print_progress(
            i,
            start,
            end,
            "log_thread_analyze_pause_start",
            "log_thread_100_percent",
            process_num,
        )
    cap.release()

def lazy_video_generate(
    process_num, start, end, cap, keep_frame_y_n, vp_y_n, fps, lgt, hgt
):
    size = (lgt, hgt)  
    out = cv2.VideoWriter(
        working_path + TEMP_PREFIX + str(process_num) + ".mp4", FOURCC, fps, size
    )
    cap.set(cv2.CAP_PROP_POS_FRAMES, start)
    for i in range(start, end):
        ret, frame = cap.read()
        if keep_frame_y_n[i] == True or vp_y_n[i] == True:
            out.write(frame)
        print_progress(
            i,
            start,
            end - 1,
            "log_thread_cut_pause_accel_start",
            "log_thread_100_percent",
            process_num,
        )

    out.release()
    # print("Thread " + str(process_num) + " generated file out_" + str(index) + vp + ".mp4")
    cap.release()

def lazy_video_generate_2(
    process_num, start_f, end_f, start, end, cap, pc, fps, lgt, hgt
):
    size = (lgt, hgt)
    out = cv2.VideoWriter(
        working_path + TEMP_PREFIX + str(process_num) + ".mp4", FOURCC, fps, size
    )
    cap.set(cv2.CAP_PROP_POS_FRAMES, start)
    skip = True
    for i in range(start, end):
        ret, frame = cap.read()
        if i < start_f or i > end_f:
            out.write(frame)
        else:
            if not is_pause(frame, pc):
                if not is_acceleration(frame, pc):
                    if skip:
                        skip = False
                    else:
                        skip = True
                        out.write(frame)
                else:
                    out.write(frame)
            print_progress(
                i,
                start,
                end - 1,
                "log_thread_cut_pause_accel_start",
                "log_thread_100_percent",
                process_num,
            )
    out.release()
    cap.release()

def lazy_version(
    video_path,
    mode,
    top_margin,
    bottom_margin,
    left_margin,
    right_margin,
    start_second,
    end_second,
    thread_num
):
    fps, lgt, hgt, frame_cnt = get_video_info(video_path)

    start_f = start_second * fps  # start frame (will keep frames before this)
    end_f = end_second * fps  # end frame   (will keep frames after this)

    pc = PointCoordinates()
    pc.calculate_or_use_coordinates(
        lgt, hgt, top_margin, bottom_margin, left_margin, right_margin
    )

    pause_y_n = np.full(frame_cnt, False)  # True means a pause, False means not a pause
    vp_y_n = np.full(frame_cnt, False)
    keep_frame_y_n = np.full(frame_cnt, False)  # True means keep, False means no keep
    frame_per_thread = math.floor(frame_cnt / thread_num)

    tc = TimeCost()

    if mode == 2:  # "Lazy mode (keep valid pauses)" index
        tc.time_start(t("log_timing_analyzing_pauses"))

        threads = []

        for thread_idx in range(thread_num):
            cap_t = cv2.VideoCapture(video_path)

            start = thread_idx * frame_per_thread
            end = (thread_idx + 1) * frame_per_thread - 1

            #print("start is", start, ", end is ", end)

            thread = threading.Thread(
                target=lazy_pause_analyze,
                args=(
                    thread_idx,
                    start_f,
                    end_f,
                    start,
                    end,
                    cap_t,
                    pc,
                    pause_y_n,
                    vp_y_n,
                    keep_frame_y_n,
                )
            )

            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        expand_valid_pause_range(frame_cnt, pause_y_n, vp_y_n)
        
        # for i in range(2760, len(keep_frame_y_n)):
            # print("i is ", i, ", keep is ", keep_frame_y_n[i])
        
        if int(e_ignore_frame_cnt.get()) > 0:
            remove_ignore_frame_cnt_part(frame_cnt, keep_frame_y_n, vp_y_n)
        
        
        tc.time_end()

        tc.time_start(t("log_timing_generating_video"))

        threads = []

        for thread_idx in range(thread_num):
            cap_t = cv2.VideoCapture(video_path)

            start = thread_idx * frame_per_thread
            end = (thread_idx + 1) * frame_per_thread if thread_idx != thread_num - 1 else frame_cnt

            thread = threading.Thread(
                target=lazy_video_generate,
                args=(thread_idx, start, end, cap_t, keep_frame_y_n, vp_y_n, fps, lgt, hgt)
            )
            threads.append(thread)
            thread.start()

            f = open(working_path + TEMP_FILENAME, "a")
            f.write("file " + TEMP_PREFIX + str(thread_idx) + ".mp4" + "\n")

        f.close()

        for thread in threads:
            thread.join()

        tc.time_end()

    elif mode == 3:  # Lazy mode (cut all pauses)
        tc.time_start(t("log_timing_generating_video"))

        threads = []

        for thread_idx in range(thread_num):
            cap_t = cv2.VideoCapture(video_path)

            start = thread_idx * frame_per_thread
            end = (thread_idx + 1) * frame_per_thread

            thread = threading.Thread(
                target=lazy_video_generate_2,
                args=(thread_idx, start_f, end_f, start, end, cap_t, pc, fps, lgt, hgt)
            )
            threads.append(thread)
            thread.start()

            f = open(working_path + TEMP_FILENAME, "a")
            f.write("file " + TEMP_PREFIX + str(thread_idx) + ".mp4" + "\n")

        f.close()

        for thread in threads:
            thread.join()

        tc.time_end()

    #cleanup below
    subprocess.call(
        "ffmpeg -loglevel quiet -f concat -safe 0 -i "
        + working_path
        + TEMP_FILENAME
        + " -c copy "
        + working_path
        + "output.mp4",
        shell=True,
    )

    os.remove(working_path + TEMP_FILENAME)
    
    cleanup(working_path)
        

def normal_get_video_audio_bounds(frame_cnt, frame_per_thread, pause_y_n, thread_num):
    bounds = [0]
    seg_cnts = [0]
    seg_cnt = 0
    check = False
    for i in range(1, frame_cnt):
        if len(bounds) == thread_num:
            break
        if pause_y_n[i] != pause_y_n[i - 1]:
            seg_cnt += 1
        if pause_y_n[i] == pause_y_n[i - 1] and i >= frame_per_thread * len(bounds):
            check = True
        elif check and pause_y_n[i] != pause_y_n[i - 1]:
            bounds += [i]
            check = False
            seg_cnts += [seg_cnt]
    return bounds, seg_cnts

def normal_pause_analyze(
    process_num, start_f, end_f, start, end, cap, pc, pause_y_n, vp_y_n
):
    if end_f < start or end < start_f:
        logger.info(t("log_thread_no_intersection").format(process_num))
    else:
        if start < start_f:
            start = start_f
        cap.set(cv2.CAP_PROP_POS_FRAMES, start)
        for i in range(start, end + 1):
            if i <= end_f:
                ret, frame = cap.read()
            if i >= start_f and i <= end:
                if is_pause(frame, pc):
                    pause_y_n[i] = True
                    if is_valid_pause(frame, pc):
                        vp_y_n[i] = True
                        #print("frame ", i, " is valid pause")
                print_progress(
                    i,
                    start,
                    end,
                    "log_thread_analyze_pause_start",
                    "log_thread_100_percent",
                    process_num,
                )
        cap.release()

def normal_video_generate(
    process_num, start_index, start, end, cap, pause_y_n, vp_y_n, fps, lgt, hgt
):
    size = (lgt, hgt) 
    index = start_index
    vp = get_file_suffix(vp_y_n[start], pause_y_n[start])
    out = cv2.VideoWriter(
        working_path + TEMP_PREFIX + str(index) + vp + ".mp4", FOURCC, fps, size
    )
    cap.set(cv2.CAP_PROP_POS_FRAMES, start)
    ret, frame = cap.read()
    out.write(frame)
    for i in range(start + 1, end):
        ret, frame = cap.read()
        if pause_y_n[i] != pause_y_n[i - 1]:
            out.release()
            # print("Thread " + str(process_num) + " generated file out_" + str(index) + vp + ".mp4")
            index += 1
            vp = get_file_suffix(vp_y_n[i], pause_y_n[i])
            out = cv2.VideoWriter(
                working_path + TEMP_PREFIX + str(index) + vp + ".mp4", FOURCC, fps, size
            )
        out.write(frame)
        print_progress(
            i,
            start + 1,
            end - 1,
            "log_thread_generate_video_start",
            "log_thread_100_percent",
            process_num,
        )

    out.release()
    # print("Thread " + str(process_num) + " generated file out_" + str(index) + vp + ".mp4")
    cap.release()

def normal_audio_generate(
    process_num, start_index, start, end, sound, pause_y_n, vp_y_n, fps
):
    start_seg = start
    inc = 1 / fps * 1000
    index = start_index
    vp = get_file_suffix(vp_y_n[start], pause_y_n[start])

    for i in range(start + 1, end):
        if pause_y_n[i] != pause_y_n[i - 1]:
            out_a = sound[start_seg * inc : i * inc + fps]
            # print("start is ", start_seg * inc, ", end is ", i * inc + fps)
            out_a.export(working_path + TEMP_PREFIX + str(index) + vp + ".mp3")
            # print("Thread " + str(process_num) + " generated file out_" + str(index) + vp + ".mp3")
            vp = get_file_suffix(vp_y_n[i], pause_y_n[i])
            index += 1
            start_seg = i
    out_a = sound[start_seg * inc : i * inc + fps]
    # print("start is ", start_seg * inc, ", end is ", i * inc + fps)
    out_a.export(working_path + TEMP_PREFIX + str(index) + vp + ".mp3")
    # print("Thread " + str(process_num) + " generated file out_" + str(index) + vp + ".mp3")

def normal_combine(process_num, prefix, start, end, has_sound, mode):
    for i in range(start, end):
        j = prefix + i
        old_name = working_path + TEMP_PREFIX + str(i)
        new_name = working_path + str(j)
        if has_sound:
            subprocess.call(
                "ffmpeg -loglevel quiet -i "
                + old_name
                + ".mp4"
                + " -i "
                + old_name
                + ".mp3"
                + " -c:v copy -c:a aac "
                + new_name
                + ".mp4",
                shell=True,
            )
            subprocess.call(
                "ffmpeg -loglevel quiet -i "
                + old_name
                + t("valid_pause") + ".mp4"
                + " -i "
                + old_name
                + t("valid_pause") + ".mp3"
                + " -c:v copy -c:a aac "
                + new_name
                + t("valid_pause") + ".mp4",
                shell=True,
            )
            if mode == 1:  # Normal mode (keep invalid pause video)
                subprocess.call(
                    "ffmpeg -loglevel quiet -i "
                    + old_name
                    + t("invalid_pause") + ".mp4"
                    + " -i "
                    + old_name
                    + t("invalid_pause") + ".mp3"
                    + " -c:v copy -c:a aac "
                    + new_name
                    + t("invalid_pause") + ".mp4",
                    shell=True,
                )
            else:
                try:
                    os.rename(                        
                        old_name + t("invalid_pause") + ".mp3",
                        new_name + t("invalid_pause") + ".mp3",
                    )
                except:
                    dummy = 0
            print_progress(
                i,
                start,
                end - 1,
                "log_thread_merge_audio_video_start",
                "log_thread_100_percent",
                process_num,
            )
            i = i + 1
        else:
            try:
                os.rename(
                    old_name + ".mp4",
                    new_name + ".mp4",
                )
            except:
                dummy = 0
            try:
                os.rename(
                    old_name + t("valid_pause") + ".mp4",
                    new_name + t("valid_pause") + ".mp4",
                )
            except:
                dummy = 0
            if mode == 1:  # Normal mode (keep invalid pause video)
                try:
                    os.rename(
                        old_name + t("invalid_pause") + ".mp4",
                        new_name + t("invalid_pause") + ".mp4",
                    )
                except:
                    dummy = 0
            print_progress(
                i,
                start,
                end - 1,
                "log_thread_no_audio_rename",
                "log_thread_100_percent",
                process_num,
            )



def normal_version(
    video_path,
    mode,
    top_margin,
    bottom_margin,
    left_margin,
    right_margin,
    start_second,
    end_second,
    thread_num
):
    fps, lgt, hgt, frame_cnt = get_video_info(video_path)

    start_f = start_second * fps  # start frame (will keep frames before this)
    end_f = end_second * fps  # end frame   (will keep frames after this)

    pc = PointCoordinates()
    pc.calculate_or_use_coordinates(
        lgt, hgt, top_margin, bottom_margin, left_margin, right_margin
    )

    pause_y_n = np.full(frame_cnt, False)  # True means a pause, False means not a pause
    vp_y_n = np.full(frame_cnt, False)

    tc = TimeCost()

    tc.time_start(t("log_timing_analyzing_pauses"))

    threads = []
    frame_per_thread = math.floor(frame_cnt / thread_num)

    for thread_idx in range(thread_num):
        # Create independent VideoCapture object to avoid resource conflicts
        cap_t = cv2.VideoCapture(video_path)

        # Calculate frame range for each thread
        start = thread_idx * frame_per_thread if thread_idx != 0 else start_f
        end = (thread_idx + 1) * frame_per_thread - 1 if thread_idx != thread_num - 1 else end_f

        # Create thread
        thread = threading.Thread(
            target=normal_pause_analyze,
            args=(thread_idx, start_f, end_f, start, end, cap_t, pc, pause_y_n, vp_y_n)
        )

        threads.append(thread)
        thread.start()

    # Wait for all threads to complete
    for thread in threads:
        thread.join()

    expand_valid_pause_range(frame_cnt, pause_y_n, vp_y_n)
    
    tc.time_end()

    tc.time_start(t("log_timing_generating_video_segments"))

    bounds, seg_cnts = normal_get_video_audio_bounds(
        frame_cnt, frame_per_thread, pause_y_n, thread_num
    )
    # print ("bounds are ", bounds)
    # print ("seg_cnts are ", seg_cnts)
    
    threads = []

    for thread_idx in range(len(bounds)):
        cap_t = cv2.VideoCapture(video_path)

        start = bounds[thread_idx]
        end = bounds[thread_idx + 1] if thread_idx != len(bounds) - 1 else frame_cnt
        start_index = seg_cnts[thread_idx]

        thread = threading.Thread(
            target=normal_video_generate,
            args=(thread_idx, start_index, start, end, cap_t, pause_y_n, vp_y_n, fps, lgt, hgt)
        )
        # print("args are ", thread_idx, start_index, start, end)
        threads.append(thread)
        thread.start()

    for thread in threads:
        thread.join()

    tc.time_end()

    has_sound = True
    try:
        sound = AudioSegment.from_file(
            video_path, format=os.path.splitext(video_path)[-1].split(".")[1]
        )
    except:
        has_sound = False

    if has_sound:
        tc.time_start(t("log_timing_generating_audio_segments"))

        threads = []

        for thread_idx in range(len(bounds)):
            start = bounds[thread_idx]
            end = bounds[thread_idx + 1] if thread_idx != len(bounds) - 1 else frame_cnt
            start_index = seg_cnts[thread_idx]

            thread = threading.Thread(
                target=normal_audio_generate,
                args=(thread_idx, start_index, start, end, sound, pause_y_n, vp_y_n, fps)
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        tc.time_end()

    working_folder_list = os.listdir(working_path)

    if has_sound:
        count = int((len(working_folder_list) - 1) / 2)
    else:
        count = len(working_folder_list) - 1

    tc.time_start(t("log_timing_merging_video_audio"))

    threads = []
    file_per_thread = math.floor(count / thread_num)

    for thread_idx in range(thread_num):

        start = thread_idx * file_per_thread
        end = (thread_idx + 1) * file_per_thread if thread_idx != thread_num - 1 else count
        prefix = pow(10, len(str(count)))

        thread = threading.Thread(
            target=normal_combine, args=(thread_idx, prefix, start, end, has_sound, mode)
        )

        threads.append(thread)
        thread.start()

    for thread in threads:
        thread.join()

    tc.time_end()

    cleanup(working_path)
    
# main here
win = Tk()
win.title(t("window_title"))

win.geometry(str(1300 + len(path.encode("utf-8")) * 5) + "x900")

l_text_working_path = Label(win, text=t("current_working_dir"), font=20, height=3)
l_working_path = Label(win, text=working_path, bg="lightgray", font=20, height=3)

l_mode = Label(win, text=t("select_mode"), font=20, height=3)
e_mode = ttk.Combobox(win, font=20, height=4, width=28)
e_mode["value"] = (t("mode_normal_audio_only"), t("mode_normal_keep_video"), t("mode_lazy_keep_valid"), t("mode_lazy_cut_all"))
win.option_add("*TCombobox*Listbox.font", 20)
e_mode.current(1)  # give default
b_show_desc = Button(win, text=t("show_desc"), command=show_desc, font=20)

# Language selector
l_language = Label(win, text=t("language"), font=20, height=2)
e_language = ttk.Combobox(win, values=["中文", "English"], font=20, width=10)
e_language.current(0 if DEFAULT_LANGUAGE == "cn" else 1)
e_language.bind("<<ComboboxSelected>>", change_language)

l_top_margin = Label(win, text=t("top_margin"), font=20, height=2)
e_top_margin = Entry(win, bg="white", font=20)

l_bottom_margin = Label(win, text=t("bottom_margin"), font=20, height=2)
e_bottom_margin = Entry(win, bg="white", font=20)

l_left_margin = Label(win, text=t("left_margin"), font=20, height=2)
e_left_margin = Entry(win, bg="white", font=20)

l_right_margin = Label(win, text=t("right_margin"), font=20, height=2)
e_right_margin = Entry(win, bg="white", font=20)

set_margin(0, 0, 0, 0)

l_thread_num = Label(win, text=t("thread_num"), font=20, height=2)
e_thread_num = Entry(win, bg="white", font=20)

e_thread_num.insert(0, DEFAULT_THREAD_NUM)

l_ignore_frame_cnt = Label(win, text=t("ignore_frame_cnt"), font=20, height=2)
e_ignore_frame_cnt = Entry(win, bg="white", font=20)

e_ignore_frame_cnt.insert(0, DEFAULT_IGNORE_FRAME_CNT)

b_save_settings = Button(
    win,
    text=t("save_settings"),
    command=lambda: save_settings(
        e_mode.current(),
        e_top_margin.get(),
        e_bottom_margin.get(),
        e_left_margin.get(),
        e_right_margin.get(),
        e_thread_num.get(),
        e_ignore_frame_cnt.get()
    ),
    font=20
)

l_measure_margin_second = Label(win, text=t("measure_margin_second"), font=20, height=2)
e_measure_margin_second = Entry(win, bg="white", font=20)

b_measure_margin = Button(
    win,
    text=t("measure_margin"),
    command=lambda: measure_margin(e_measure_margin_second.get()),
    font=20
)
b_crop = Button(
    win,
    text=t("crop_btn"),
    command=lambda: crop(
        e_top_margin.get(),
        e_bottom_margin.get(),
        e_left_margin.get(),
        e_right_margin.get()
    ),
    font=20
)

b_cut_without_crop = Button(
    win,
    text=t("start_without_crop"),
    command=lambda: cut_without_crop(
        e_mode.current(),
        e_top_margin.get(),
        e_bottom_margin.get(),
        e_left_margin.get(),
        e_right_margin.get(),
        e_start_second.get(),
        e_end_second.get(),
        e_thread_num.get(),
        e_ignore_frame_cnt.get()
    ),
    font=20
)
b_cut_with_crop = Button(
    win,
    text=t("start_with_crop"),
    command=lambda: cut_with_crop(
        e_mode.current(),
        e_start_second.get(),
        e_end_second.get(),
        e_thread_num.get(),
        e_measure_margin_second.get(),
        e_ignore_frame_cnt.get()
    ),
    font=20
)

l_tutorial = Label(win, text=t("tutorial"), font=20, height=2)

ft = tkFont.Font(family="Fixdsys", size=11, weight=tkFont.NORMAL, underline=1)
l_tutorial_url = Label(
    win, text="www.bilibili.com/video/BV1qg411r7dV", font=ft, fg="blue", height=2
)
l_tutorial_url.bind("<ButtonPress-1>", jump_to_tutorial)


l_start_second = Label(win, text=t("start_second"), font=20, height=2)
e_start_second = Entry(win, bg="white", font=20)

l_end_second = Label(win, text=t("end_second"), font=20, height=2)
e_end_second = Entry(win, bg="white", font=20)




l_manual_set_second = Label(win, text=t("manual_set_second"), font=20, height=2)
e_manual_set_second_1 = Entry(win, bg="white", font=20, width=10)
e_manual_set_second_2 = Entry(win, bg="white", font=20, width=10)
b_manual_set = Button(
    win,
    text=t("manual_set"),
    command=lambda: set_coordinates_manually(e_manual_set_second_1.get(),e_manual_set_second_2.get()),
    font=20
)
b_manual_set_sample = Button(
    win,
    text=t("sample_images"),
    command=lambda: set_coordinates_sample(),
    font=20
)
b_manual_set_save = Button(
    win,
    text=t("save_detection_points"),
    command=lambda: manual_set_save(),
    font=20
)
l_pause_middle = Label(win, text="y,x", font=20, height=2)
l_pause_left = Label(win, text="y,x", font=20, height=2)

l_frame_desc = Label(win, text=t("refer_sample"), font=20, height=2)
l_frame_1_desc = Label(win, text=t("frame_1_desc"), font=20, height=2)
l_frame_2_desc = Label(win, text=t("frame_2_desc"), font=20, height=2)

l_acc_left = Label(win, text="y,x", font=20, height=2)
l_acc_right = Label(win, text="y,x", font=20, height=2)

l_middle_pause_middle_2 = Label(win, text="y,x", font=20, height=2)
l_middle_pause_left = Label(win, text="y,x", font=20, height=2)
l_middle_pause_middle = Label(win, text="y,x", font=20, height=2)
l_middle_pause_right = Label(win, text="y,x", font=20, height=2)

l_valid_pause = Label(win, text="y,x1,x2,x3,x4", font=20, height=2)
#l_valid_pause_2 = Label(win, text="y,x1,x2,x3,x4", font=20, height=2)

l_manual_set_or_not = Label(win, text=t("manual_set_or_not"), font=20, height=3)

e_manual_set_or_not = ttk.Combobox(win, values=(t("no"), t("yes")), font=20, height=4, width=10)
e_manual_set_or_not.current(0)
e_manual_set_second_1.config(state="disabled")
e_manual_set_second_2.config(state="disabled")
b_manual_set.config(state="disabled")
b_manual_set_sample.config(state="disabled")  
b_manual_set_save.config(state="disabled")  
e_manual_set_or_not.bind("<<ComboboxSelected>>", update_entry_state)

l_text_working_path.grid(row=0)
l_working_path.grid(row=0, column=1)
l_language.grid(row=0, column=2)
e_language.grid(row=0, column=3)
l_mode.grid(row=1)
e_mode.grid(row=1, column=1)
b_show_desc.grid(row=1, column=2)

l_top_margin.grid(row=4)
e_top_margin.grid(row=4, column=1)
l_bottom_margin.grid(row=5)
e_bottom_margin.grid(row=5, column=1)
l_left_margin.grid(row=6)
e_left_margin.grid(row=6, column=1)
l_right_margin.grid(row=7)
e_right_margin.grid(row=7, column=1)

l_thread_num.grid(row=8)
e_thread_num.grid(row=8, column=1)

l_ignore_frame_cnt.grid(row=9)
e_ignore_frame_cnt.grid(row=9, column=1)

b_save_settings.grid(row=10)

l_measure_margin_second.grid(row=11)
e_measure_margin_second.grid(row=11, column=1)
b_measure_margin.grid(row=12)
b_crop.grid(row=12, column=1)

l_start_second.grid(row=13)
e_start_second.grid(row=13, column=1)
l_end_second.grid(row=14)
e_end_second.grid(row=14, column=1)

b_cut_without_crop.grid(row=15, column=0)
b_cut_with_crop.grid(row=15, column=1)
l_tutorial.grid(row=16, column=0)
l_tutorial_url.grid(row=16, column=1)

l_manual_set_or_not.grid(row=4, column=2)
e_manual_set_or_not.grid(row=4, column=3)
l_manual_set_second.grid(row=5, column=2)
e_manual_set_second_1.grid(row=5, column=3)
e_manual_set_second_2.grid(row=5, column=4)
b_manual_set.grid(row=6, column=2)
b_manual_set_sample.grid(row=6, column=3)
b_manual_set_save.grid(row=6,column=4)
l_acc_right.grid(row=7, column=2)
l_acc_left.grid(row=8, column=2)
l_frame_desc.grid(row=7, column=3, columnspan=2)
l_frame_1_desc.grid(row=8, column=3, columnspan=2)
l_frame_2_desc.grid(row=9, column=3, columnspan=2)
l_pause_middle.grid(row=9, column=2)
l_pause_left.grid(row=10, column=2)
l_middle_pause_left.grid(row=11, column=2)
l_middle_pause_middle_2.grid(row=12, column=2)
l_middle_pause_middle.grid(row=13, column=2)
l_middle_pause_right.grid(row=14, column=2)
l_valid_pause.grid(row=15, column=2)
#l_valid_pause_2.grid(row=16, column=2)


if os.path.exists(path + "/设置.txt"):
    f = open(path + "/设置.txt")
    e_mode.current(int(f.readline()))
    set_margin(
        int(f.readline()), int(f.readline()), int(f.readline()), int(f.readline())
    )
    set_thread_num(int(f.readline()))
    set_ignore_frame_cnt(int(f.readline()))
    # Read language preference (new field)
    lang_line = f.readline().strip()
    if lang_line:
        set_language(lang_line)  # Use i18n function
        current_language = get_current_language()
        e_language.current(0 if current_language == "cn" else 1)
        update_all_text()
    f.close()

set_coordinates()

# Register language change callback
register_language_change_callback(update_all_text)

win.mainloop()
